import glob
import json
import os
import re
import zipfile
from urllib.request import urlretrieve

import pandas as pd
import requests


# Necessary metadata
article_id = 14226968  # this is the unique identifier of the article on figshare
url = f"https://api.figshare.com/v2/articles/{article_id}"
headers = {"Content-Type": "application/json"}
output_directory = "/srv/data/my_shared_data_folder/"


response = requests.request("GET", url, headers=headers)
data = json.loads(
    response.text
)  # this contains all the articles data, feel free to check it out
files = data["files"]  # this is just the data about the files, which is what we want
files


files_to_dl = [
    "combined_model_data_parti.parquet.zip"
]  ## Please download the partitioned
for file in files:
    if file["name"] in files_to_dl:
        os.makedirs(output_directory, exist_ok=True)
        urlretrieve(file["download_url"], output_directory + file["name"])


with zipfile.ZipFile(
    os.path.join(output_directory, "combined_model_data_parti.parquet.zip"), "r"
) as f:
    f.extractall(output_directory)


# Passing your credentials
with open("credentials.json") as f:
    aws_credentials = json.load(f)

df_combined = pd.read_parquet(
    "s3://mds-s3-group02/combined_model_data_parti.parquet/",
    storage_options=aws_credentials,
)


df_combined.head()


df_combined.shape


df_SYD = pd.read_csv(
    "s3://mds-s3-group02/observed_daily_rainfall_SYD.csv",
    storage_options=aws_credentials,
)


df_SYD.head()


df_SYD.shape


syd_lat = -33.86
syd_lon = 151.21
sydney = (
    df_combined.query("lat_min <= @syd_lat <= lat_max & lon_min <= @syd_lon <= lon_max")
    .drop(columns=["lat_min", "lat_max", "lon_min", "lon_max"])
    .set_index("time")
)
sydney.index = pd.to_datetime(sydney.index)


sydney.head()


sydney.shape


# wrangle the data
sydney = sydney.pivot(columns="model", values="rain (mm/day)").resample("1D").mean()


sydney.head()


sydney.shape


# load observed data
observed = pd.read_csv(
    "s3://mds-s3-group02/observed_daily_rainfall_SYD.csv",
    storage_options=aws_credentials,
).set_index("time")
observed.index = pd.to_datetime(observed.index)
observed.columns = ["Observed"]


observed.head()


observed.shape


ml_data_SYD = pd.concat([sydney, observed], axis=1)


ml_data_SYD.head()


ml_data_SYD.shape


ml_data_SYD.to_csv(
    "s3://mds-s3-group02/output/ml_data_SYD.csv", storage_options=aws_credentials
)



